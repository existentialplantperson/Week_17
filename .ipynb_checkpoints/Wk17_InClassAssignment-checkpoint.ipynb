{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7a0641",
   "metadata": {},
   "source": [
    "1. Write simple (straightforward) definitions for the following parameters for RandomForestClassifier \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html and indicate how they correlate with the precision and recall for the basic diabetes model we built in class. You will need to rerun the model multiple times to do so.\n",
    "\n",
    "Parameter- Correlation with Precision - Correlation with Recall\n",
    "- estimators\n",
    "    - precision - positive correlation\n",
    "    - recall - positive correlation\n",
    "    - description - the number of trees to build before aggregating the data together, more estimators means a more accurate representation of the data and so precision and recall are increased\n",
    "- max_depth\n",
    "    - precision - \n",
    "    - recall - \n",
    "    - decision - this parameter controls the depth of the tree, the number of levels of splitting\n",
    "- min_samples_split\n",
    "    - precision - \n",
    "    - recall - \n",
    "- min_samples_leaf\n",
    "    - precision - \n",
    "    - recall - \n",
    "- min_weight_fraction_leaf\n",
    "    - precision - positive\n",
    "    - recall - negative\n",
    "    - description - default is 0, very small changes affected the results\n",
    "- max_leaf_nodes\n",
    "    - precision - positive\n",
    "    - recall - positive\n",
    "    - description - controls the maximum number of final leaf nodes, increasing the number of nodes increases the precision and recall to the point of overfitting \n",
    "- min_impurity_decrease - \"A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\"\n",
    "    - precision - negative correlation\n",
    "    - recall - negative correlation\n",
    "    - description - default is 0, a threshold for splitting a node based on the data is in the parent node; larger values create a large threshold for splitting and decrease precision and recall by preventing data points from being accurately categorized; this affects the minority class the most\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773b0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e44f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('../Datasets/diabetes.csv')\n",
    "\n",
    "# seperate target variable and features\n",
    "X = diabetes.drop('Outcome', axis=1)\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "#split data into training and validation sets using resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=66)\n",
    "\n",
    "#define standardizing object\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4041861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82       160\n",
      "           1       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.35      0.50      0.41       231\n",
      "weighted avg       0.48      0.69      0.57       231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aspen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aspen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aspen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_impurity_decrease = 0.1, random_state=66)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "#rf.score(X_test, y_test)\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7502661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       160\n",
      "           1       0.61      0.54      0.57        71\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.71      0.69      0.70       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_impurity_decrease = 0.01, random_state=66)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "#rf.score(X_test, y_test)\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa753d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29342a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.85       160\n",
      "           1       0.85      0.24      0.37        71\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.80      0.61      0.61       231\n",
      "weighted avg       0.78      0.75      0.70       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth = 1, random_state=66)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "#rf.score(X_test, y_test)\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ed5a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       160\n",
      "           1       0.62      0.68      0.64        71\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.73      0.74      0.74       231\n",
      "weighted avg       0.78      0.77      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth = 10, random_state=66)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "#rf.score(X_test, y_test)\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8d62c",
   "metadata": {},
   "source": [
    "2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so.\n",
    "\n",
    "Bootstrapping means pulling random samples of the data rather than running the classifier on all of the data. It did moderately affect the precision and recall, but not by much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
